# ðŸš€ AI Providers Configuration
# Dynamic AI Providers System - Configuration File
# This file defines all available AI providers, their capabilities, and fallback chains

version: "1.0"
metadata:
  description: "AI Providers configuration for AI-chan"
  created: "2025-09-08"
  last_updated: "2025-09-08"

# Global settings
global_settings:
  default_timeout_seconds: 30
  max_retries: 3
  retry_delay_seconds: 1
  enable_fallback: true
  log_provider_usage: true
  debug_mode: false

# AI Providers Configuration
ai_providers:
  openai:
    enabled: true
    priority: 1
    display_name: "OpenAI GPT"
    description: "OpenAI models with advanced text generation, image analysis, and creation"
    
    capabilities:
      - text_generation
      - image_generation
      - image_analysis
      - audio_generation
      - audio_transcription
      - realtime_conversation
      - function_calling
    
    api_settings:
      base_url: "https://api.openai.com"
      version: "v1"
      authentication_type: "bearer_token"
      required_env_keys:
        - "OPENAI_API_KEYS"
    
    models:
      text_generation:
        - "gpt-5"
        - "gpt-5-mini"
        - "gpt-4.1"
        - "gpt-4.1-mini"
      image_generation:
        - "gpt-5"
        - "gpt-5-mini"
        - "gpt-4.1"
        - "gpt-4.1-mini"
      image_analysis:
        - "gpt-5"
        - "gpt-5-mini"
        - "gpt-4.1"
        - "gpt-4.1-mini"
      audio_generation:
        - "gpt-4o-mini-tts"
      audio_transcription:
        - "gpt-4o-mini-transcribe"
      realtime_conversation:
        - "gpt-realtime"
    
    defaults:
      text_generation: "gpt-4.1-mini"
      image_generation: "gpt-4.1-mini"
      image_analysis: "gpt-4.1-mini"
      audio_generation: "gpt-4o-mini-tts"
      audio_transcription: "gpt-4o-mini-transcribe"
      realtime_conversation: "gpt-realtime"
    
    # Voice configuration for TTS and Realtime
    voices:
      # All available voices (from kOpenAIVoiceGender - exact match)
      available:
        - "sage"
        - "alloy"
        - "ash"
        - "ballad"
        - "coral"
        - "echo"
        - "fable"
        - "onyx"
        - "nova"
        - "shimmer"
        - "verse"
        - "cedar"
        - "marin"
      
      default: "marin"          # Default voice for both TTS and Realtime
      tts_default: "marin"      # TTS default (same as general default)
    
    # Realtime Configuration (gpt-realtime specific)
    realtime:
      enabled: true
      models:
        - "gpt-realtime"
      default_model: "gpt-realtime"
      
      # Advanced gpt-realtime features
      features:
        voice_instructions: true
        async_function_calling: true
        image_input: true
        language_switching: true
        non_verbal_cues: true
        premium_voices: true
        multimodal_realtime: true
      
      # Supported languages for dynamic switching
      supported_languages:
        - "en"  # English
        - "es"  # Spanish
        - "fr"  # French
        - "de"  # German
        - "it"  # Italian
        - "pt"  # Portuguese
        - "zh"  # Chinese
        - "ja"  # Japanese
        - "ko"  # Korean
        - "ru"  # Russian
        - "ar"  # Arabic
      
      default_language: "es"
      
      # Voice instruction presets
      voice_instruction_presets:
        professional: "speak in a clear, professional tone"
        casual: "speak in a relaxed, conversational manner"
        enthusiastic: "speak with energy and enthusiasm"
        calm: "speak in a calm, soothing voice"
        confident: "speak with confidence and authority"
        quick: "speak quickly and efficiently"
      
      default_voice_instructions: "speak in a clear, professional tone"
    
    # Hybrid System Configuration (TTS + STT + Text fallback)
    hybrid_fallback:
      enabled: true
      prefer_realtime: true  # Try realtime first, fallback if needed
      
      # TTS settings for hybrid mode
      tts_settings:
        model: "tts-1-hd"
        voice: "alloy"
        speed: 1.0
        quality: "hd"
      
      # STT settings for hybrid mode  
      stt_settings:
        model: "whisper-1"
        language: "es"
        response_format: "json"
        temperature: 0.0
      
      # Text model for hybrid processing
      text_model: "gpt-4"
      
      # Fallback triggers
      fallback_conditions:
        - "realtime_unavailable"
        - "connection_issues"
        - "model_overloaded"
        - "user_preference"
      
    rate_limits:
      requests_per_minute: 3500
      tokens_per_minute: 350000
    
    configuration:
      max_context_tokens: 128000
      max_output_tokens: 4096
      supports_streaming: true
      supports_function_calling: true
      supports_tools: true

  google:
    enabled: true
    priority: 2
    display_name: "Google Gemini"
    description: "Google Gemini models with multimodal capabilities"
    
    capabilities:
      - text_generation
      - image_generation
      - image_analysis
      - realtime_conversation
    
    api_settings:
      base_url: "https://generativelanguage.googleapis.com"
      version: "v1beta"
      authentication_type: "api_key"
      required_env_keys:
        - "GEMINI_API_KEYS"
    
    models:
      text_generation:
        - "gemini-2.5-flash"
        - "gemini-2.5-pro"
      image_generation:
        - "gemini-2.5-flash-image-preview"
      image_analysis:
        - "gemini-2.5-flash"
      realtime_conversation:
        - "gemini-2.5-flash"
        - "gemini-2.5-pro"
    defaults:
      text_generation: "gemini-2.5-flash"
      image_generation: "gemini-2.5-flash-image-preview"
      image_analysis: "gemini-2.5-flash"
      realtime_conversation: "gemini-2.5-flash"
    
    # Voice configuration (Google TTS via Cloud Text-to-Speech API)
    voices:
      available:
        - "es-ES-Neural2-A"
        - "es-ES-Neural2-B"
        - "es-ES-Neural2-C"
        - "es-ES-Neural2-D"
        - "es-ES-Standard-A"
        - "es-ES-Standard-B"
        - "es-ES-Standard-C"
        - "es-ES-Standard-D"
        - "es-US-Neural2-A"
        - "es-US-Neural2-B"
        - "es-US-Neural2-C"
        - "es-US-Standard-A"
        - "es-US-Standard-B"
        - "es-US-Standard-C"
      default: "es-ES-Neural2-A"
    
    # Google Hybrid System (TTS + STT + Text)
    hybrid_system:
      enabled: true  # Google doesn't have native realtime, so hybrid is primary
      
      # Google TTS configuration
      tts_provider: "google_cloud_tts"
      tts_settings:
        voice_name: "es-ES-Neural2-A"
        language_code: "es-ES"
        ssml_gender: "FEMALE"
        audio_encoding: "MP3"
        speaking_rate: 1.0
        pitch: 0.0
        volume_gain_db: 0.0
      
      # Google STT configuration
      stt_provider: "google_cloud_stt"
      stt_settings:
        language_code: "es-ES"
        model: "latest_long"
        enable_automatic_punctuation: true
        enable_word_time_offsets: true
        use_enhanced: true
      
      # Text model for processing
      text_model: "gemini-2.5-flash"
    
    rate_limits:
      requests_per_minute: 2000
      tokens_per_minute: 1000000
    
    configuration:
      max_context_tokens: 1000000
      max_output_tokens: 8192
      supports_streaming: true
      supports_function_calling: true
      supports_tools: false

  xai:
    enabled: true
    priority: 3
    display_name: "X.AI Grok"
    description: "X.AI Grok models for advanced reasoning and text generation"
    
    capabilities:
      - text_generation
      - image_analysis
    
    api_settings:
      base_url: "https://api.x.ai"
      version: "v1"
      authentication_type: "bearer_token"
      required_env_keys:
        - "GROK_API_KEYS"
    
    models:
      text_generation:
        - "grok-4"
        - "grok-3"
        - "grok-2"
        - "grok-beta"
        - "grok-vision-beta"
      image_analysis:
        - "grok-vision-beta"
        - "grok-4"
    
    defaults:
      text_generation: "grok-4"
      image_analysis: "grok-vision-beta"
    
    # XAI Hybrid System (TTS + STT + Text only - no native voice capabilities)
    hybrid_system:
      enabled: true  # XAI requires hybrid for voice functionality
      
      # Use external TTS service (fallback to OpenAI TTS)
      tts_provider: "external_openai"
      tts_settings:
        model: "tts-1"
        voice: "alloy"
        speed: 1.0
      
      # Use external STT service (fallback to OpenAI Whisper)
      stt_provider: "external_openai" 
      stt_settings:
        model: "whisper-1"
        language: "es"
        response_format: "json"
      
      # XAI text model for processing
      text_model: "grok-4"
    
    rate_limits:
      requests_per_minute: 5000
      tokens_per_minute: 200000
    
    configuration:
      max_context_tokens: 131072
      max_output_tokens: 4096
      supports_streaming: false
      supports_function_calling: false
      supports_tools: false

# Fallback chains define which providers to try in sequence for each capability
fallback_chains:
  text_generation:
    primary: "google"
    fallbacks:
      - "openai"
      - "xai"
    
  image_generation:
    primary: "openai"
    fallbacks:
      - "google"
    
  image_analysis:
    primary: "openai"
    fallbacks:
      - "google"
    
  audio_generation:
    primary: "openai"
    fallbacks: []
  
  audio_transcription:
    primary: "openai"
    fallbacks: []
    
  realtime_conversation:
    primary: "openai"  # OpenAI has native gtp-realtime support
    fallbacks:
      - "google"       # Google hybrid system
      - "xai"          # XAI hybrid system

# Realtime Service Global Configuration
realtime_service:
  # Service behavior settings
  auto_fallback: true              # Automatically fallback if realtime fails
  prefer_native_realtime: true     # Prefer native realtime over hybrid
  hybrid_as_primary: false        # Use hybrid only as fallback
  
  # Performance and reliability
  connection_timeout: 30           # seconds
  response_timeout: 10             # seconds
  max_retries: 3
  retry_delay: 1                   # seconds
  
  # Audio settings
  audio_format: "pcm16"            # Default audio format
  sample_rate: 24000               # Default sample rate
  chunk_size: 1024                 # Audio chunk size
  
  # Language and voice defaults
  default_language: "es"
  default_voice: "marin"            # Simple: just the voice name
  
  # Feature flags
  enable_voice_instructions: true
  enable_async_function_calling: true
  enable_multimodal_input: true
  enable_language_switching: true
  enable_non_verbal_cues: true

# Environment-specific overrides
# TEMPORALMENTE COMENTADO PARA TESTING - PROBLEMAS CON MERGE DE CONFIGURACIONES
# environments:
#   development:
#     global_settings:
#       debug_mode: true
#       log_provider_usage: true
#     
#     ai_providers:
#       openai:
#         defaults:
#           text_generation: "gpt-4.1-mini"  # Use cheaper model in dev
#       google:
#         defaults:
#           text_generation: "gemini-2.5-flash"  # Use faster model in dev
#   
#   production:
#     global_settings:
#       debug_mode: false
#       log_provider_usage: false
#     
#     ai_providers:
#       openai:
#         defaults:
#           text_generation: "gpt-4.1"  # Use better model in prod
#       google:
#         defaults:
#           text_generation: "gemini-2.5"  # Use better model in prod

# Advanced routing rules
routing_rules:
  # Route image generation requests to specific providers based on request type
  image_generation:
    avatar_requests:
      preferred_provider: "openai"
      fallback_providers: ["google"]
    
    creative_requests:
      preferred_provider: "google"
      fallback_providers: ["openai"]
  
  # Route based on context length
  text_generation:
    long_context:
      threshold_tokens: 50000
      preferred_provider: "google"  # Gemini has 1M token context
      fallback_providers: ["openai", "xai"]
    
    short_context:
      threshold_tokens: 50000
      preferred_provider: "openai"
      fallback_providers: ["google", "xai"]

# Health check configuration
health_checks:
  enabled: true
  interval_minutes: 5
  timeout_seconds: 10
  failure_threshold: 3
  success_threshold: 2
