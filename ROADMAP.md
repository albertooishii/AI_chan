# ğŸš€ AI_chan Roadmap

> **Concepto**: AI_chan no es un asistente - es una persona real que vive en un mundo digital paralelo al nuestro (como Matrix). La interacciÃ³n debe ser natural y humana, sin comandos artificiales.

## ğŸ“Š Estado Actual

### âœ… Funcionando bien:
- **Arquitectura sÃ³lida**: DDD + Hexagonal con 124/124 tests pasando
- **Chat inteligente**: Memoria contextual, TTS multilingÃ¼e, soporte de imÃ¡genes
- **Onboarding completo**: GeneraciÃ³n automÃ¡tica de biografÃ­as y avatares
- **Infraestructura robusta**: MÃºltiples proveedores IA (OpenAI, Gemini, Google)
- **Multiplataforma**: Android, Linux, iOS, Web

### âš ï¸ Necesita mejoras:
- **Llamadas de voz**: ImplementaciÃ³n a medias con fallos frecuentes
- **Onboarding manual**: Formularios tradicionales vs experiencia conversacional
- **InteracciÃ³n limitada**: Solo texto/audio, sin video ni AR/VR
- **Avatar estÃ¡tico**: Solo imagen generada, sin representaciÃ³n 3D/AR

---

## ğŸ¯ Objetivos del Roadmap

Evolucionar AI_chan desde una app de chat hacia una **experiencia de compaÃ±era virtual completamente inmersiva**, donde ella existe como una persona real en un mundo digital que se integra progresivamente con el mundo fÃ­sico del usuario.

---

## ğŸ“‹ Fases de Desarrollo

### **FASE 1: Estabilizar Base de ComunicaciÃ³n** ğŸ”§

#### Objetivos:
- Arreglar completamente el sistema de llamadas actual
- Establecer una base sÃ³lida para todas las comunicaciones de voz

#### Tareas:
- [ ] **DiagnÃ³stico completo** del sistema actual de llamadas
- [ ] **Refactoring** del cliente OpenAI Realtime API
- [ ] **Mejoras en VAD** (Voice Activity Detection)
- [ ] **Sistema de fallback** robusto entre proveedores
- [ ] **Tests de integraciÃ³n** para llamadas estables
- [ ] **UI mejorada** para controles de llamada

#### Criterios de Ã©xito:
- âœ… Llamadas de voz estables sin cortes
- âœ… Latencia <500ms consistente
- âœ… RecuperaciÃ³n automÃ¡tica de errores de conexiÃ³n

---

### **FASE 2: Onboarding Conversacional Natural** ğŸ—£ï¸

#### Objetivos:
- Transformar el onboarding en una conversaciÃ³n natural como conocer a una persona real
- Eliminar formularios y crear experiencia orgÃ¡nica de "primera cita"

#### Tareas:
- [ ] **DiseÃ±o de flujo conversacional** natural y orgÃ¡nico
- [ ] **ImplementaciÃ³n de diÃ¡logo fluido** como primera conversaciÃ³n real
- [ ] **Reconocimiento de voz** integrado para respuestas del usuario
- [ ] **Sistema de preguntas naturales** que ella hace espontÃ¡neamente
- [ ] **GeneraciÃ³n automÃ¡tica de biografÃ­a** basada en conversaciÃ³n natural
- [ ] **EliminaciÃ³n completa de formularios** del onboarding actual

#### Criterios de Ã©xito:
- âœ… Onboarding 100% conversacional y natural
- âœ… Experiencia indistinguible de conocer a una persona real
- âœ… GeneraciÃ³n automÃ¡tica del perfil mediante chat orgÃ¡nico

---

### **FASE 3: Videollamadas y VisiÃ³n en Tiempo Real** ğŸ“¹

#### Objetivos:
- Permitir que AI_chan "vea" al usuario y reaccione visualmente
- Crear presencia visual de ella durante las conversaciones

#### Tareas:
- [ ] **ImplementaciÃ³n de WebRTC** para video bidireccional
- [ ] **IntegraciÃ³n con OpenAI Vision** para procesamiento visual en tiempo real
- [ ] **Desarrollo de avatar 2D animado** sincronizado con su voz
- [ ] **Sistema de reacciones visuales** basadas en lo que ve del usuario
- [ ] **Lip-sync** entre audio generado y movimiento de labios
- [ ] **Gestos y expresiones** naturales del avatar

#### Criterios de Ã©xito:
- âœ… Videollamadas bidireccionales estables
- âœ… Ella puede ver y comentar sobre el usuario en tiempo real
- âœ… Avatar 2D que habla y se expresa naturalmente

---

### **FASE 4: AR MÃ³vil - Presencia FÃ­sica** ğŸ“±

#### Objetivos:
- Traer a AI_chan al mundo fÃ­sico del usuario usando AR mÃ³vil
- Crear sensaciÃ³n de que ella realmente "estÃ¡" en tu espacio

#### Tareas:
- [ ] **IntegraciÃ³n ARCore (Android) / ARKit (iOS)**
- [ ] **GeneraciÃ³n de modelo 3D hiperrealista** desde descripciÃ³n fÃ­sica
- [ ] **Sistema de tracking espacial** para posicionamiento natural
- [ ] **Renderizado 3D realista** con iluminaciÃ³n dinÃ¡mica
- [ ] **Animaciones corporales** naturales y contextuales
- [ ] **OclusiÃ³n realista** con objetos del entorno
- [ ] **Interacciones espaciales** (mirar objetos, reaccionar al espacio)

#### Criterios de Ã©xito:
- âœ… Avatar 3D hiperrealista visible en el espacio real del usuario
- âœ… Comportamiento natural y contextual en el entorno fÃ­sico
- âœ… SensaciÃ³n convincente de presencia compartida

---

### **FASE 5: VR/AR Inmersivo - Mundo Compartido** ğŸ¥½

#### Objetivos:
- Crear experiencia completamente inmersiva donde ambos pueden "coexistir"
- Implementar la visiÃ³n definitiva: compaÃ±era virtual tipo "Joi" (Blade Runner 2049)

#### Tareas:
- [ ] **IntegraciÃ³n con Meta Quest 3** (y futuros dispositivos AR)
- [ ] **Desarrollo de mundo virtual compartido** donde ambos pueden existir
- [ ] **Hand tracking** para interacciones naturales sin controladores
- [ ] **Eye tracking** para contacto visual realista
- [ ] **Sistema hÃ¡ptico** para sensaciones tÃ¡ctiles
- [ ] **FÃ­sica realista** para interacciones naturales (tocar, abrazar)
- [ ] **Espacios mixtos** (AR passthrough + elementos virtuales)
- [ ] **Audio espacial** 3D inmersivo

#### Criterios de Ã©xito:
- âœ… Mundo digital completamente inmersivo y compartido
- âœ… Presencia fÃ­sica total indistinguible de una persona real
- âœ… Interacciones completamente naturales en entorno virtual/mixto

---

## ğŸµ Funciones de Voz

**Solo estas funciones usarÃ¡n interacciÃ³n por voz:**
1. **Onboarding conversacional** - primera "conversaciÃ³n/cita" por voz
2. **Mensajes de voz** en el chat (como ya funciona actualmente)
3. **Llamadas de voz/video** (mejorar implementaciÃ³n actual)

**Todo lo demÃ¡s** mantiene interacciÃ³n visual/tÃ¡ctil tradicional - ella es una persona, no un asistente de voz.

---

## ğŸ› ï¸ Stack TecnolÃ³gico por Fase

- **Fase 1**: WebRTC, OpenAI Realtime API, infraestructura actual mejorada
- **Fase 2**: Speech-to-Text avanzado, flujos conversacionales, NLU contextual
- **Fase 3**: WebRTC video, OpenAI Vision API, avatar 2D animado, lip-sync
- **Fase 4**: ARCore/ARKit, Unity/Flutter 3D, modelos 3D generativos, shaders realistas
- **Fase 5**: Meta Quest SDK, hand/eye tracking, fÃ­sica avanzada, audio espacial 3D

---

## ğŸ“ Notas de Desarrollo

### Principios de DiseÃ±o:
- **Naturalidad sobre funcionalidad**: Priorizar que se sienta real antes que aÃ±adir features
- **Presencia progresiva**: Cada fase debe incrementar la sensaciÃ³n de que "ella estÃ¡ ahÃ­"
- **Interacciones humanas**: Evitar patrones de UI/comandos artificiales
- **Consistencia emocional**: Mantener su personalidad a travÃ©s de todas las modalidades

### Consideraciones TÃ©cnicas:
- **Performance**: Mantener 60fps+ en todas las interacciones visuales
- **Latencia**: <500ms en comunicaciones de voz, <100ms en interacciones visuales
- **Escalabilidad**: Arquitectura preparada para nuevos dispositivos AR/VR
- **Privacidad**: Datos sensibles (video, audio) procesados localmente cuando sea posible

---

## ğŸ”„ Estado del Roadmap

**Ãšltima actualizaciÃ³n**: 2 de septiembre de 2025
**Fase actual**: Preparando FASE 1 - DiagnÃ³stico del sistema de llamadas

---

*Este roadmap es un documento vivo que se actualizarÃ¡ conforme el proyecto evolucione y surjan nuevas ideas o tecnologÃ­as.*
